{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Clone Tensorflow Models Repository**"
      ],
      "metadata": {
        "id": "CUZNAsPbmtxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEnUVIYAmm0u",
        "outputId": "96b2afce-4cc7-4226-a65b-a8f3327a310e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 97156, done.\u001b[K\n",
            "remote: Counting objects: 100% (436/436), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 97156 (delta 250), reused 380 (delta 228), pack-reused 96720\u001b[K\n",
            "Receiving objects: 100% (97156/97156), 612.86 MiB | 17.51 MiB/s, done.\n",
            "Resolving deltas: 100% (70662/70662), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Protobuf**\n",
        "No need to do this if you are on Colab.\n",
        "\n",
        "If you're doing this locally, download the latest Protobuf library for your OS from https://github.com/google/protobuf/releases\n",
        "\n",
        "The filename should look like \"protoc--.zip\".\n",
        "\n",
        "Assuming you've unzipped this zip file to \\<path>, the next step is to add \\<path>/bin to your PATH environment variable (on Linux or Mac).\n",
        "\n",
        "Once Protobuf has been successfully installed, you can run the following command (note: must be done from the models/research folder)."
      ],
      "metadata": {
        "id": "mRP8cGe9mys2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "zbJ8tNSCm1Ne"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install the object detection API**"
      ],
      "metadata": {
        "id": "4WezLAKrm5w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models/research && \\\n",
        "    cp object_detection/packages/tf2/setup.py . && \\\n",
        "    python -m pip install ."
      ],
      "metadata": {
        "id": "XmXpgeSgm8tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Installation (Optional)**"
      ],
      "metadata": {
        "id": "b4Zs8rwem_pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd models/research && python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "8E77zffRm9rW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "UcUG5hKKnEoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "A5kNO8vknG4T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "8w-6ZmA0nIa_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download Videos**"
      ],
      "metadata": {
        "id": "3MASppLwnKzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob3nN1W2nNh0",
        "outputId": "09c67dd8-a036-477d-f737-6d917323c615"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-01 14:52:35--  https://lazyprogrammer.me/course_files/cnn_class2_videos.zip\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3031::6815:17d2, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2073140 (2.0M) [application/zip]\n",
            "Saving to: ‘cnn_class2_videos.zip’\n",
            "\n",
            "\rcnn_class2_videos.z   0%[                    ]       0  --.-KB/s               \rcnn_class2_videos.z 100%[===================>]   1.98M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-05-01 14:52:35 (33.2 MB/s) - ‘cnn_class2_videos.zip’ saved [2073140/2073140]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tzXqYBOnOsX",
        "outputId": "e6c311ef-38dd-48dc-ebd7-59c886619524"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cnn_class2_videos.zip\n",
            "  inflating: catdog.mp4              \n",
            "  inflating: safari.mp4              \n",
            "  inflating: traffic.mp4             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYUub1K5nPyH",
        "outputId": "50e25891-113c-4e1d-edfe-b4ebef274555"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "catdog.mp4  cnn_class2_videos.zip  models  safari.mp4  sample_data  traffic.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEOS = ['catdog', 'safari', 'traffic']"
      ],
      "metadata": {
        "id": "a6uxPlgrnToW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download and extract model files**\n",
        "Get URLs from the \"Object Detection Zoo\": https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
      ],
      "metadata": {
        "id": "OzdNpJ22nSIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
        "\n",
        "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
        "    fname='ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n",
        "    origin=url,\n",
        "    untar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6GcGelrnQ5H",
        "outputId": "fd0ea16b-168d-4aed-e4c1-0f99441699d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "\u001b[1m386527459/386527459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_MODEL_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rCgELjmwnJex",
        "outputId": "e8263109-9002-4c02-d89e-556f9f420e10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download Labels File**\n",
        "Label files can be found here: https://github.com/tensorflow/models/tree/master/research/object_detection/data\n",
        "\n",
        "You probably won't need these since Object Detection Zoo contains only models trained on COCO."
      ],
      "metadata": {
        "id": "FHf2vCyznePF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "\n",
        "PATH_TO_LABELS = tf.keras.utils.get_file(\n",
        "    fname='mscoco_label_map.pbtxt',\n",
        "    origin=url,\n",
        "    untar=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHucs-ZlnjTX",
        "outputId": "dac3fa83-3cc2-4b75-9073-33c92090e2e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
            "\u001b[1m5056/5056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bHw3us-FnkZY",
        "outputId": "b90d9c81-bd78-4ebe-8977-fd53152c7c6d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/mscoco_label_map.pbtxt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {PATH_TO_LABELS}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf6x6DionlXA",
        "outputId": "ab434ac0-3e87-4ccd-bf86-22e230c43a48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item {\n",
            "  name: \"/m/01g317\"\n",
            "  id: 1\n",
            "  display_name: \"person\"\n",
            "}\n",
            "item {\n",
            "  name: \"/m/0199g\"\n",
            "  id: 2\n",
            "  display_name: \"bicycle\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load in the model**"
      ],
      "metadata": {
        "id": "Q8lggr0Knmxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVUagY41np-p",
        "outputId": "c3dc081f-5d47-47bd-d4a3-0e4bf1d8cbbb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...Done! Took 35.65617918968201 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load in the labels**"
      ],
      "metadata": {
        "id": "sUfavAhenqvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    PATH_TO_LABELS,\n",
        "    use_display_name=True)"
      ],
      "metadata": {
        "id": "jJbWhg6gns7F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjXIo0l1nuCp",
        "outputId": "508deebc-3fa8-4869-c234-022afdad09bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'person'},\n",
              " 2: {'id': 2, 'name': 'bicycle'},\n",
              " 3: {'id': 3, 'name': 'car'},\n",
              " 4: {'id': 4, 'name': 'motorcycle'},\n",
              " 5: {'id': 5, 'name': 'airplane'},\n",
              " 6: {'id': 6, 'name': 'bus'},\n",
              " 7: {'id': 7, 'name': 'train'},\n",
              " 8: {'id': 8, 'name': 'truck'},\n",
              " 9: {'id': 9, 'name': 'boat'},\n",
              " 10: {'id': 10, 'name': 'traffic light'},\n",
              " 11: {'id': 11, 'name': 'fire hydrant'},\n",
              " 13: {'id': 13, 'name': 'stop sign'},\n",
              " 14: {'id': 14, 'name': 'parking meter'},\n",
              " 15: {'id': 15, 'name': 'bench'},\n",
              " 16: {'id': 16, 'name': 'bird'},\n",
              " 17: {'id': 17, 'name': 'cat'},\n",
              " 18: {'id': 18, 'name': 'dog'},\n",
              " 19: {'id': 19, 'name': 'horse'},\n",
              " 20: {'id': 20, 'name': 'sheep'},\n",
              " 21: {'id': 21, 'name': 'cow'},\n",
              " 22: {'id': 22, 'name': 'elephant'},\n",
              " 23: {'id': 23, 'name': 'bear'},\n",
              " 24: {'id': 24, 'name': 'zebra'},\n",
              " 25: {'id': 25, 'name': 'giraffe'},\n",
              " 27: {'id': 27, 'name': 'backpack'},\n",
              " 28: {'id': 28, 'name': 'umbrella'},\n",
              " 31: {'id': 31, 'name': 'handbag'},\n",
              " 32: {'id': 32, 'name': 'tie'},\n",
              " 33: {'id': 33, 'name': 'suitcase'},\n",
              " 34: {'id': 34, 'name': 'frisbee'},\n",
              " 35: {'id': 35, 'name': 'skis'},\n",
              " 36: {'id': 36, 'name': 'snowboard'},\n",
              " 37: {'id': 37, 'name': 'sports ball'},\n",
              " 38: {'id': 38, 'name': 'kite'},\n",
              " 39: {'id': 39, 'name': 'baseball bat'},\n",
              " 40: {'id': 40, 'name': 'baseball glove'},\n",
              " 41: {'id': 41, 'name': 'skateboard'},\n",
              " 42: {'id': 42, 'name': 'surfboard'},\n",
              " 43: {'id': 43, 'name': 'tennis racket'},\n",
              " 44: {'id': 44, 'name': 'bottle'},\n",
              " 46: {'id': 46, 'name': 'wine glass'},\n",
              " 47: {'id': 47, 'name': 'cup'},\n",
              " 48: {'id': 48, 'name': 'fork'},\n",
              " 49: {'id': 49, 'name': 'knife'},\n",
              " 50: {'id': 50, 'name': 'spoon'},\n",
              " 51: {'id': 51, 'name': 'bowl'},\n",
              " 52: {'id': 52, 'name': 'banana'},\n",
              " 53: {'id': 53, 'name': 'apple'},\n",
              " 54: {'id': 54, 'name': 'sandwich'},\n",
              " 55: {'id': 55, 'name': 'orange'},\n",
              " 56: {'id': 56, 'name': 'broccoli'},\n",
              " 57: {'id': 57, 'name': 'carrot'},\n",
              " 58: {'id': 58, 'name': 'hot dog'},\n",
              " 59: {'id': 59, 'name': 'pizza'},\n",
              " 60: {'id': 60, 'name': 'donut'},\n",
              " 61: {'id': 61, 'name': 'cake'},\n",
              " 62: {'id': 62, 'name': 'chair'},\n",
              " 63: {'id': 63, 'name': 'couch'},\n",
              " 64: {'id': 64, 'name': 'potted plant'},\n",
              " 65: {'id': 65, 'name': 'bed'},\n",
              " 67: {'id': 67, 'name': 'dining table'},\n",
              " 70: {'id': 70, 'name': 'toilet'},\n",
              " 72: {'id': 72, 'name': 'tv'},\n",
              " 73: {'id': 73, 'name': 'laptop'},\n",
              " 74: {'id': 74, 'name': 'mouse'},\n",
              " 75: {'id': 75, 'name': 'remote'},\n",
              " 76: {'id': 76, 'name': 'keyboard'},\n",
              " 77: {'id': 77, 'name': 'cell phone'},\n",
              " 78: {'id': 78, 'name': 'microwave'},\n",
              " 79: {'id': 79, 'name': 'oven'},\n",
              " 80: {'id': 80, 'name': 'toaster'},\n",
              " 81: {'id': 81, 'name': 'sink'},\n",
              " 82: {'id': 82, 'name': 'refrigerator'},\n",
              " 84: {'id': 84, 'name': 'book'},\n",
              " 85: {'id': 85, 'name': 'clock'},\n",
              " 86: {'id': 86, 'name': 'vase'},\n",
              " 87: {'id': 87, 'name': 'scissors'},\n",
              " 88: {'id': 88, 'name': 'teddy bear'},\n",
              " 89: {'id': 89, 'name': 'hair drier'},\n",
              " 90: {'id': 90, 'name': 'toothbrush'}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Do some Object Detection**"
      ],
      "metadata": {
        "id": "yoA6lPGFnwdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects_in_image(image_np):\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "    return image_np_with_detections\n",
        "\n",
        "\n",
        "def detect_objects_in_video(input_video):\n",
        "    print(f'Running inference for {input_video}.mp4... ', end='')\n",
        "\n",
        "    video_reader = imageio.get_reader(f'{input_video}.mp4')\n",
        "    video_writer = imageio.get_writer(f'{input_video}_annotated.mp4', fps=10)\n",
        "\n",
        "    # loop through and process each frame\n",
        "    t0 = time.time()\n",
        "    n_frames = 0\n",
        "    for frame in video_reader:\n",
        "        n_frames += 1\n",
        "        new_frame = detect_objects_in_image(frame)\n",
        "\n",
        "        # instead of plotting image, we write the frame to video\n",
        "        video_writer.append_data(new_frame)\n",
        "\n",
        "    fps = n_frames / (time.time() - t0)\n",
        "    print(\"Frames processed: %s, Speed: %s fps\" % (n_frames, fps))\n",
        "\n",
        "    # clean up\n",
        "    video_writer.close()"
      ],
      "metadata": {
        "id": "w6nY0Xt0nzJX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtpwDR5Sn0wH",
        "outputId": "9a2ed269-64d7-45de-b473-aa425489c6eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference for catdog.mp4... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames processed: 50, Speed: 0.20051522328643662 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S9fGkhcn2XZ",
        "outputId": "cc2216d7-b50b-4fd5-ef05-5c481e90abb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference for safari.mp4... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (640, 360) to (640, 368) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames processed: 100, Speed: 0.21678922189252772 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IdY9dO2n4cS",
        "outputId": "be57b1d0-9640-4279-d5f9-765b131e3cae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference for traffic.mp4... Frames processed: 70, Speed: 0.21937633412228122 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Recall that the neural network accepts batches of inputs\n",
        "\n",
        "# Instead of trying to predict each frame one by one, use batches instead."
      ],
      "metadata": {
        "id": "1gHInc1wqG2r"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: use your webcam instead."
      ],
      "metadata": {
        "id": "0Uwx5Tavn7Kf"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}